---
title: "TeTRA-VPR: A Ternary Transformer Approach for Compact Visual Place Recognition"
date: "2025-03-04"
categories: ["Projects", "Computer Vision"]
tags: ["Visual Place Recognition", "PyTorch", "Quantization", "Transformer"]
description: "A compact and efficient approach for Visual Place Recognition using extreme low-bit quantization and progressive distillation."
---

<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <title>TeTRA-VPR: A Ternary Transformer Approach for Compact Visual Place Recognition</title>
  </head>
  <body>
    <h1>TeTRA-VPR: Compact and Efficient Visual Place Recognition</h1>
    <p>
      <strong>TeTRA-VPR</strong> is an innovative project that employs extreme low-bit quantization for Vision Transformers to tackle Visual Place Recognition. By combining progressive quantization-aware training with knowledge distillation, the approach reduces the backbone to ternary precision and compresses the final embeddings to binary.
    </p>
    <p>
      This method achieves up to <strong>69% lower memory usage</strong> and <strong>35% lower inference latency</strong> compared to efficient baselines, all while maintaining high retrieval accuracy. The system is implemented using <strong>PyTorch Lightning</strong> with dedicated scripts for pre-training and fine-tuning, ensuring robust performance across diverse conditions.
    </p>
    
    <!-- Embedded demo video or project overview -->
    <iframe width="560" height="315" src="https://www.youtube.com/embed/example" 
            frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
    </iframe>
  </body>
</html>
